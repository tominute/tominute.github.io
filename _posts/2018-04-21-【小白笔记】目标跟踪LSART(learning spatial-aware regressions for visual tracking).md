
---
layout:     post
title:      【小白笔记】目标跟踪LSART(learning spatial-aware regressions for visual tracking)
date:       2018-04-21
author:     tominute
header-img: img/post-bg-android.jpg
catalog: true
tags:
    - Tracking
---

# 1.主要贡献
这篇文章发表于CVPR18上，是spotlight文章，从思路来说并不难，下面就来说一下这篇文章吧，有不对的地方欢迎一起讨论~ 
 
<br />**贡献1**：这个算法使用了将KRR(核相关滤波)和CNN(卷积神经网络)方法结合的方式来进行目标跟踪(就是每个模型的response加权求和)，作者将传统迭代求解KRR的方法运用神经网络的方式求解(这个有意思)，比传统方式更有效；\\  
<br />**贡献2**：将空域正则化的核用在卷积神经网络中，这样网络输出的每一层都可以对特定的局部区域有响应，并且作者使用了距离变化池化层(distance transform pooling layer)来卷积层输出的有效性。
# 2.核化岭回归模型(KRR)
### 2.1 一个新的核

首先给出岭回归模型原空间的解如下
![1](/img/20180421/1.jpg)
然后给出对偶空间的解并运用核技巧如下
![2](/img/20180421/2.jpg)
作者想出了一个新的核，把每个图像等分分成M块小区域，这样计算核即计算两个图像所有小区域的相关加权和，即
![3](/img/20180421/3.jpg)
通过设置加权系数可以使这个核满足对称性，作者设计这个核的主要目的是使模型能够更多的关注图像的不同子区域之间的相似性，加权系数也可通过计算自适应的调整子区域的相似性，这样能使模型更有判别性。
把3式带入2式得到如下4式
![4](/img/20180421/4.jpg)
这个式子比较繁琐，将它等价简化成矩阵形式如下
![5](/img/20180421/5.jpg)
注意这里
${\bf f}_m = [{\bf x}_1^m,...,{\bf x}_N^m]$即N个样本的第m的子区域的矩阵集合形式，5式中y后面一项就是检测时计算的响应，下面还会用到。
传统的解法是迭代分别求解$\alpha$和$\beta$,复杂度较高，这里作者巧妙的使用了卷积网络的思想求解。


### 2.2 构建KRR的卷积网络模型
还是看我们上面说的那个响应
![6](/img/20180421/6.jpg)
通过网络的方式构建出这个表达，利用反向传播求解未知参数$\alpha$和$\beta$，然后前向计算出响应不就达到我们KRR的目的了吗，多么简单明了，那么我们就需要把$\alpha$和$\beta$设计成卷积网络里的卷积核就可以了，作者这样分成了三步
![7](/img/20180421/7.jpg)
网络图模型如下
![8](/img/20180421/8.jpg)
**模块A**：首先以目标框两倍大小裁剪出大样本，然后基于目标框的大小在大样本中滑动密集采样得到N个样本并向量化为d=h*w*C维，得到一个大的特征矩阵就是d×N维的，$\alpha$就是一个N×1的向量，这样D乘a就实现了对N个样本的加权求和，得到Z，把Z恢复成h*w*C的尺寸再等分成M个小块，这样每一个小块就是对应于$w_m^t$。\\
**模块B**：这个理解稍微费点劲，我们把A得到的每个w拼起来作为一个M通道的卷积核，那么B式表达的意思就是在每个${\bf f}_m$上用w对每一个样本的每一个小区域做一个相关，注意我们样本是密集采样的，那么每一个小区域在大样本上看也是密集连续采样的，就像下图表示的一样
![9](/img/20180421/9.jpg)
那么我们可以用卷积的方法快速计算，首先采出每一个${\bf f}_m$对应于大样本上的区域，然后分别做卷积，再把所有小区域卷积的结果合起来得到M个(H-h+1)×(W-w+1)×M的输出。\\
**模块C**：这个简单，这是把M个输出结果加权求和，对应于用一个$1*1*M^2$的卷积核的卷积操作，这样所有未知参数都变成了网络中的权值，利用反传算法即可求解。
模型更新方式比较常规这里就不说了。


# 3.CNN模型
看懂上面一节这里就不难了，主要是搭建网络模型。作者把测试和训练过程分成了两个网络，卷积层都只有两层，两个网络分别叫net-B和net-C，这是为了避免过拟合和在训练的时候考虑旋转因素。两个模型如下
![10](/img/20180421/10.jpg)
都选择了VGG-16的conv4-3层结果作为输入，第一层卷积核采用了100个5*5的空间正则的核，第二层核是3*3 的，输出的每一个通道都是目标位置的响应图，共100个响应图分成25组，每一组4个map加起来，然后把25个map送到距离变换层。
对于net-C，分成了两条支线，上半条路径和net-B一样，但是下半条使用了旋转180°后的样本作为输入，前两层卷积和net-B一样，然后对上下两个支路出来的各100个map使用max-out池化的操作得到100个最终的map，然后计算每个map的loss再反传计算网络参数，loss对应的标准输出是高斯map。
这样得到的网络能够比较好的处理旋转问题，net-C的每个部分是独立训练的避免过拟合。\\
**空间正则的核**\\
看一下公式
![11](/img/20180421/11.jpg)
$W_c$表示了每一通道的惩罚系数，这个系数矩阵可以用伯努利分布预先生成，相当于一个二进制的掩膜。目的是使滤波器关注于不同区域（其实我觉得这就是利用SRDCF的思想，压制不同区域的响应）。\\
**距离变换池化层**\\
看一下公式就行了，感觉就是trick。
![12](/img/20180421/12.jpg)

# 4.KRR和CNN结合
这个方法很naive，就是把两个方法得到的map加权求和，KRR的方法更关注于整体，CNN方法更关注局部。
![13](/img/20180421/13.jpg)
尺度估计使用了类似SAMF的方法。其他没啥了，实验速度1fps，性能和CCOT相当，再次膜拜Martin大神。
欢迎讨论~~
