---
layout:     post
title:      【小白笔记】目标跟踪VIVAT(Visual Tracking via Adversarial Learning)论文笔记
date:       2018-05-27
author:     tominute
header-img: img/post-bg-os-metro.jpg
catalog: true
tags:
    - Tracking
---

# 1. 主要贡献
这篇文章是18CVPR的spotlight文章，👉[论文地址](https://arxiv.org/pdf/1804.04273.pdf)，首次结合了对抗学习的思路用在目标跟踪上，并取得了不错的效果，跟踪性能和ECO相当，速度为1.5fps。下面就来说一下这篇文章吧，有不对的地方欢迎一起讨论~ 
 
<br />**贡献1**：运用GAN在特征空间来进行正样本扩增，使得能够在长时间范围内获得大量的外观变化从而获得更加鲁棒的效果，特别是当目标被遮挡或旋转时，漂移的现象会得到削弱；\\   
<br />**贡献2**：针对跟踪问题中负样本远远多于正样本的问题，不同于困难样本挖掘和给样本加权的方法，提出了一种高阶的代价敏感损失函数，即使用了focal loss的方法来解决跟踪问题中的样本不平衡问题。 其中对抗学习用在了最后一层卷积层和全连接层之间，用来生成不同的mask，作用在特征上可以获得不同外观变化的特征，mask的学习是通过选择masks中loss最大的作为mask，这样可以降低具有判别力特征的影响力从而获得鲁棒性。 
# 2. 主要思路

该算法中的CNN不仅用来提特征还用来分类，把分类器理解为判别器D，另外提出了一个对抗学习中的生成器。和传统对抗学习任务不同，这里的生成器是为了获得一个对目标变化鲁棒的判别器。
![1](/img/20180527/1.png)

### 2.1 对抗学习
来看使用交叉熵损失的目标函数
![2](/img/20180527/2.png)
G和D网络是同时训练的，对G来说目的是让G(z)尽量接近x使D判别不出来，对D来说就是要努力提高正确判别x和概率降低判别G(z)的概率。训练完之后G被移除仅保留D进行测试。

**问题**：\\
检测-跟踪的框架不能直接使用这个公式，原因有二，文中第三点有问题。\\
一：跟踪的输入是许多候选目标块而不是随机噪声；\\
二：我们需要用有标签的样本进行分类器的训练而非是无标签的；\\

所以作者提出了新的架构缩小了GAN和跟踪架构的距离。看图一，作者把G放在了提特征和分类器的中间，G用来生成一个带权模板作用在特征上，初始模板随机给定然后通过对抗学习的过程来识别有判别力的特征，C是输入特征，G(C)是带权单通道模板，尺度和C一样，而实际上能够识别强判别力特征的模板是M，这样就得到新的目标函数如下。
![3](/img/20180527/3.png)
明显看出这个公式多了一个正则项，这个M怎么得到的呢，下面会说。输入还是候选图像块，但是在训练D的时候我们提取特征且在特征空间丰富了特征表达，这是通过G生成的许多模板作用在特征上实现的而不是使用传统的数据扩增手段。初始时随机给几个模板，每个模板都可以看成对特征外观变化的一种特定操作(强行解释），通过对抗学习过程，G会逐渐得到最能使判别器误判的那个模板，这就意味着G学到的模板能够识别出有判别力或者说干扰力的特征。而D也不会对特定帧的判别力强的特征过拟合因为有G的存在不断给D干扰来迫使D的判别更加鲁棒。训练时先训D再训G。

**训练D**：\\
一次迭代中使输入特征进入G得到一个模板G(C)，然后再作用到特征上再传给D，然后通过监督学习的方法训练D，因为输入有很多因此也会生成很多模板。所以D将会关注于时间上更鲁棒的特征而不是单帧判别力强的特征。

**训练G**：\\
训练完D后，给一个输入特征会得到很多输出特征，因为上一步得到的模板很多啊，这些特征都送给D然后选出损失最大的那个对应的模板，说明这个模板能够有效降低强判别力特征的影响，然后把这个模板作为上面公式中的标准M了。

**可视化的解释**：\\
我们可以通过D得到的分类概率来计算熵，熵越大说明预测的不确定性越高，下面这个图很直观，当目标旋转了一下，没有GAN的熵立刻变高了，说明加了GAN能够增强结果的鲁棒性。
![4](/img/20180527/4.png)

### 2.2 价值敏感损失函数
使用交叉熵的损失函数有一个问题，就是那些很假的负样本(就是预测分类概率远小于0.5且预测为负样本的)的量很大的时候，它会占据交叉熵损失的一大部分从而主导了反传的梯度，跟踪的任务中类别数量就是不平衡的，正样本少，负样本多，很假的负样本就更多了，为了改进作者引入了focal loss的想法，直接用来改进目标函数，能够削弱这种影响。有兴趣的同学可以阅读👉[focal loss](https://arxiv.org/abs/1708.02002 )的文章。
![5](/img/20180527/5.png)

### 2.3跟踪流程
**初始化**\\
第一步使用训练数据离线预训练；\\
第二步提取第一帧的样本在线finetune。

**检测**\\
移除了G网络，给一帧图，生成一些候选区域块给CNN提特征再给D网络得到预测的概率值。

**模型更新**\\
每一帧进行增量更新，在估计的位置周围生成一些样本并给标签，然后用这些样本训练G和D。
实验在OTB和VOT上都做了性能和ECO相当。
